---
permalink: /
title: "Hi! I'm Liza üëãüèº"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
---
I am an AI Alignment researcher looking to build moral alignment _into_ AI agents. Until recently I've been studying this problem in my PhD through multi-agent simulations with independent learning agents, using systems based on Reinforcement Learning (RL) and foundation models (LLMs such as Gemma2), with inspiration from moral philosophy, psychology and game theory. Now I am a Student Researcher at Google DeepMind.

In my latest work I have developed a methodology for quantifying key moral philosophical frameworks in terms of actions and consequences on an environment, modeled these as intrinsic rewards for training RL agents playing social dilemma games (see [IJCAI'23 paper](https://doi.org/10.24963/ijcai.2023/36)), simulated societies of agents with diverse moral preferences, implemented multi-agent RL with partner selection, investigated coalition formation, the emergence of cooperation and exploitation in morally heterogeneous societies (see [AIES'24 paper](https://arxiv.org/abs/2403.04202)), and applied this framework to fine-tuning LLM agents to play more morally aligned policies in interactive game environments (see [ICLR'25 paper](https://arxiv.org/abs/2410.01639)).  

I did my PhD at the [Machine Intelligence Lab](https://www.machineintelligencelab.ai/), Department of Computer Science, University College London (UCL). I was funded by the Leverhulme Doctoral Training Programme for the Ecological Study of the Brain. Before my PhD I studied Psychology & Linguistics (@ UCL), conducted computational social science research in political psychology using Twitter data (@ University of Cambridge), and worked as an AI/Data Scientist and Behavioural Scientist at two start-ups and a large investment bank. 

News
======
---
- [Jan 2026] Presented an invited talk at the AAAI'26 Workshop: [From Formal Methods to Emergent Machine Ethics](https://www.aialign.net/ws-machine-ethics)! Slides [here](https://docs.google.com/presentation/d/1MDhWgh2MuRo2LaRbrbwVf4-k58ic1yuxqybb9YxIRRA/edit?usp=sharing).
- [Sep-Jan 2025] Presented talks at UK Multi-Agent Systems meetup (@ KCL); ARENA 6.0 & 7.0 courses (@ LISA); Citizen-Centric AI Systems Seminar (online) 
- [Jul 2025] I've started at DeepMind as a Student Researcher! 
- [Jun 2025] Presented a poster and a workshop lightning talk at the [RLDM](https://rldm.org/) conference in Dublin.
- [May 2025] Took part in the [ARENA](https://www.arena.education/) accelerator & presented a talk at LISA in London. Our capstone project has now been written up [on LW](https://www.lesswrong.com/posts/ZdY4JzBPJEgaoCxTR/emergent-misalignment-and-realignment)! 
- [Apr 2025] Presenting our [paper](https://arxiv.org/abs/2410.01639) at [ICLR 2025](https://iclr.cc/) in Singapore, plus three workshop papers. Also attending the Alignment Workshop by FAR AI. 
- [Mar 2025] Presenting a poster at the [UK Multi-Agent Systems Symposium](https://www.turing.ac.uk/events/uk-multi-agent-systems-symposium-2025-uk-mas) at the Turing Institute in London. 
- [Jan 2025] Our paper "Moral Alignment for LLM Agents" ([see preprint](https://arxiv.org/abs/2410.01639)) has been accepted for the 13th International Conference on Learning Representations (ICLR'25) in Singapore. 
- [Jan 2025] Gave an invited talk at the Political Psychology Lab at Cambridge on Moral Alignment for Agentic AI Systems.
- [Dec 2024] Presented my team's work at the [Concordia LLM Agent Competition](https://neurips.cc/virtual/2024/competition/84791) at NeurIPS'24 (remotely). 
- [Oct 2024] New preprint out: Moral Alignment for LLM Agents ([see arXiv](https://arxiv.org/abs/2410.01639))
- [July 2024] Our paper "Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents" ([see arXiv](https://arxiv.org/html/2403.04202v2)) has been accepted for The 7th AAAI/ACM Conference on AI, Ethics & Society, 2024 (San Jose, California).
- [July 2024] Attending at the [Vienna Alignment Workshop ](https://far.ai/post/2024-08-vienna-alignment-workshop/#:~:text=The%20Vienna%20Alignment%20Workshop%20advanced,Workshops%2C%20register%20your%20interest%20here.) and presenting our work at the Unconference which followed :) 
- [July 2024] I'm at the [Eastern European Machine Learning Summer School](https://www.eeml.eu/home) in Novi Sad, Serbia! 
- [April 2024] I'm at the InterpViz Mechanistic Interpretability hackathon at LISA (The London Initiative for Safe AI)! 
- [March 2024] New preprint out: Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents ([see arXiv](https://arxiv.org/html/2403.04202v2))
- [December 2023] New preprint out: Learning Machine Morality through Experience and Interaction ([see arXiv](https://arxiv.org/abs/2312.01818))
- [November 2023] Gave a (long) student talk at LSE about how AI and Social Science can mutually benefit one another, and interesting questions emerging around aligning LLMs with human values.
- [November 2023] I'm at the Anthropic Hackathon in London!
- [November 2023] Presenting our IJCAI paper at two UCL Conferences - the Computer Science Student Conference (long talk) and the Neuro AI Conference (lightning talk). 
- [August 2023] Presented our paper ‚ÄúModeling Moral Choices in Social Dilemmas with Multi-Agent Reinforcement Learning‚Äù at the [32nd International Joint Conference on Artificial Intelligence (IJCAI 2023)](https://ijcai-23.org/) (main track) in Macao. Links & materials [here](https://liza-tennant.github.io/publication/2023-modeling-moral-choices).
- [July 2023] I'm at the [Cooperative AI Foundation](https://www.cooperativeai.com/) Summer School in London! 
- [May 2023] Spent a week volunteering at the [22nd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2023)](https://aamas2023.soton.ac.uk/) in London.

Education
====
---
- PhD Computer Science (Leverhulme Doctoral Training Programme for the Ecological Study of the Brain), University College London, 2022-2025. 
- MPhil Biological Science (Psychology), University of Cambridge, 2019-2020. Full-time research, based at the [Political Psychology Lab](https://www.psychol.cam.ac.uk/polpsych). In my research I studied political and linguistic behaviour on Twitter using Social Network Analysis and Natural Language Processing.
- BSc Psychology & Language Sciences, University College London, 2016-2019.


Previous experience
======
---
- Researcher (contract), pre-seed agent startup, 2024-2025. 
- Quantitative UX Researcher, JPMorgan (user experience analytics within the Corporate & Investment Bank, Markets business), 2021-2022.
- Data & Behavioural Scientist, Rooster Insurance (car insurance startup which based its pricing model on behavioural data rather than demographcis), 2021.
- Behavioural & AI Scientist, ProdX.ai (productivity startup which was building a product to make digital workers more productive thourgh automated, data-driven & psychology-inspired coaching), 2020.


Other
======
---
I've changed my last name from Karmannaya to Tennant. If you see different names listed on different publications, don't get confused :)
